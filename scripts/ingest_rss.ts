
#!/usr/bin/env tsx
import Parser from "rss-parser"; import { JSDOM } from "jsdom"; import { readFile } from "fs/promises"; import path from "path"; import { fileURLToPath } from "url"; import { PrismaClient } from "@prisma/client";
const prisma=new PrismaClient(); const parser=new Parser(); const __dirname=path.dirname(fileURLToPath(import.meta.url));
async function extractText(html?:string){ if(!html) return null; const dom=new JSDOM(html); const doc=dom.window.document; return doc.body?.textContent?.replace(/\s+/g," ").trim()??null; }
async function callWorker(articleId: bigint){ const url=process.env.WORKER_URL||"http://localhost:8000/enrich"; try{ await fetch(url,{method:"POST",headers:{"content-type":"application/json","x-api-key":process.env.WORKER_API_KEY||""}, body:JSON.stringify({article_id:String(articleId)})}); }catch(e){ console.error("Worker call failed:",e); } }
async function main(){ const feedsPath=path.join(__dirname,"../feeds/feeds.json"); const feeds=JSON.parse(await readFile(feedsPath,"utf8")); for(const f of feeds.rss){ console.log("Fetching",f.name,f.url); const feed=await parser.parseURL(f.url); const source=await prisma.source.findUnique({where:{url:f.url}}); if(!source) continue; for(const item of feed.items.slice(0,20)){ const url=item.link!; try{ const exists=await prisma.article.findUnique({where:{url}}); if(exists) continue; const rawText=await extractText((item as any)["content:encoded"]||item.content||""); const title=item.title?.trim()||"(untitled)"; const publishedAt=item.isoDate?new Date(item.isoDate):new Date(); const article=await prisma.article.create({data:{sourceId:source.id,url,title,publishedAt,summary:item.contentSnippet?.substring(0,500)||null,rawText}}); await callWorker(article.id); console.log("Stored + queued:",title);}catch(e){ console.error("Ingest error:",e);} } } }
main().finally(async()=>prisma.$disconnect());
